{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289ebffa-0fef-45c0-a9dc-3ce52103cc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b3589f9-7eaf-455b-8e85-5a59479bdf1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Read the dataset:\n",
    "file = open(\"/Users/diego/Scripts/og-language-models/tiny-shakespeare.txt\", \"r\")\n",
    "contents = file.read()\n",
    "#print(contents)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d067c9f-44ed-4e55-ba97-4d1cc7772cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "vocabulary = list(set(contents))\n",
    "vocabulary = sorted(vocabulary)\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4896c6a-1e1f-4a9b-9cc6-bf215e10ee74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Length:  65\n",
      "Content Length:  1115393\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocabulary Length: \", len(vocabulary))\n",
    "print(\"Content Length: \", len(contents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5761a703-34cd-44f4-ad32-7cff767b1ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 43, 50, 50, 53, 1, 35, 53, 56, 50, 42]\n",
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "## First we must make encode and decoder functions for our dataset\n",
    "string_to_int = {ch : i for i, ch in enumerate(vocabulary)}\n",
    "int_to_string = {i : ch for i, ch in enumerate(vocabulary)}\n",
    "encode = lambda s : [string_to_int[c] for c in s]\n",
    "decode = lambda l : ''.join([int_to_string[i] for i in l])\n",
    "print(encode(\"Hello World\"))\n",
    "print(decode(encode(\"Hello World\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f11b58ba-50c2-4fc2-88b7-76ce0af285b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
      "         1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
      "        53,  1, 42, 47, 43,  1, 58, 46, 39, 52,  1, 58, 53,  1, 44, 39, 51, 47,\n",
      "        57, 46, 12,  0,  0, 13, 50, 50, 10,  0, 30, 43, 57, 53, 50, 60, 43, 42,\n",
      "         8,  1, 56, 43, 57, 53, 50, 60, 43, 42,  8,  0,  0, 18, 47, 56, 57, 58,\n",
      "         1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 18, 47, 56, 57, 58,  6,  1, 63,\n",
      "        53, 59,  1, 49, 52, 53, 61,  1, 15, 39, 47, 59, 57,  1, 25, 39, 56, 41,\n",
      "        47, 59, 57,  1, 47, 57,  1, 41, 46, 47, 43, 44,  1, 43, 52, 43, 51, 63,\n",
      "         1, 58, 53,  1, 58, 46, 43,  1, 54, 43, 53, 54, 50, 43,  8,  0,  0, 13,\n",
      "        50, 50, 10,  0, 35, 43,  1, 49, 52, 53, 61,  5, 58,  6,  1, 61, 43,  1,\n",
      "        49, 52, 53, 61,  5, 58,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 24, 43, 58,  1, 59, 57,  1, 49, 47, 50, 50,  1,\n",
      "        46, 47, 51,  6,  1, 39, 52, 42,  1, 61, 43,  5, 50, 50,  1, 46, 39, 60,\n",
      "        43,  1, 41, 53, 56, 52,  1, 39, 58,  1, 53, 59, 56,  1, 53, 61, 52,  1,\n",
      "        54, 56, 47, 41, 43,  8,  0, 21, 57,  5, 58,  1, 39,  1, 60, 43, 56, 42,\n",
      "        47, 41, 58, 12,  0,  0, 13, 50, 50, 10,  0, 26, 53,  1, 51, 53, 56, 43,\n",
      "         1, 58, 39, 50, 49, 47, 52, 45,  1, 53, 52,  5, 58, 11,  1, 50, 43, 58,\n",
      "         1, 47, 58,  1, 40, 43,  1, 42, 53, 52, 43, 10,  1, 39, 61, 39, 63,  6,\n",
      "         1, 39, 61, 39, 63,  2,  0,  0, 31, 43, 41, 53, 52, 42,  1, 15, 47, 58,\n",
      "        47, 64, 43, 52, 10,  0, 27, 52, 43,  1, 61, 53, 56, 42,  6,  1, 45, 53,\n",
      "        53, 42,  1, 41, 47, 58, 47, 64, 43, 52, 57,  8,  0,  0, 18, 47, 56, 57,\n",
      "        58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 35, 43,  1, 39, 56, 43,  1,\n",
      "        39, 41, 41, 53, 59, 52, 58, 43, 42,  1, 54, 53, 53, 56,  1, 41, 47, 58,\n",
      "        47, 64, 43, 52, 57,  6,  1, 58, 46, 43,  1, 54, 39, 58, 56, 47, 41, 47,\n",
      "        39, 52, 57,  1, 45, 53, 53, 42,  8,  0, 35, 46, 39, 58,  1, 39, 59, 58,\n",
      "        46, 53, 56, 47, 58, 63,  1, 57, 59, 56, 44, 43, 47, 58, 57,  1, 53, 52,\n",
      "         1, 61, 53, 59, 50, 42,  1, 56, 43, 50, 47, 43, 60, 43,  1, 59, 57, 10,\n",
      "         1, 47, 44,  1, 58, 46, 43, 63,  0, 61, 53, 59, 50, 42,  1, 63, 47, 43,\n",
      "        50, 42,  1, 59, 57,  1, 40, 59, 58,  1, 58, 46, 43,  1, 57, 59, 54, 43,\n",
      "        56, 44, 50, 59, 47, 58, 63,  6,  1, 61, 46, 47, 50, 43,  1, 47, 58,  1,\n",
      "        61, 43, 56, 43,  0, 61, 46, 53, 50, 43, 57, 53, 51, 43,  6,  1, 61, 43,\n",
      "         1, 51, 47, 45, 46, 58,  1, 45, 59, 43, 57, 57,  1, 58, 46, 43, 63,  1,\n",
      "        56, 43, 50, 47, 43, 60, 43, 42,  1, 59, 57,  1, 46, 59, 51, 39, 52, 43,\n",
      "        50, 63, 11,  0, 40, 59, 58,  1, 58, 46, 43, 63,  1, 58, 46, 47, 52, 49,\n",
      "         1, 61, 43,  1, 39, 56, 43,  1, 58, 53, 53,  1, 42, 43, 39, 56, 10,  1,\n",
      "        58, 46, 43,  1, 50, 43, 39, 52, 52, 43, 57, 57,  1, 58, 46, 39, 58,  0,\n",
      "        39, 44, 44, 50, 47, 41, 58, 57,  1, 59, 57,  6,  1, 58, 46, 43,  1, 53,\n",
      "        40, 48, 43, 41, 58,  1, 53, 44,  1, 53, 59, 56,  1, 51, 47, 57, 43, 56,\n",
      "        63,  6,  1, 47, 57,  1, 39, 57,  1, 39, 52,  0, 47, 52, 60, 43, 52, 58,\n",
      "        53, 56, 63,  1, 58, 53,  1, 54, 39, 56, 58, 47, 41, 59, 50, 39, 56, 47,\n",
      "        57, 43,  1, 58, 46, 43, 47, 56,  1, 39, 40, 59, 52, 42, 39, 52, 41, 43,\n",
      "        11,  1, 53, 59, 56,  0, 57, 59, 44, 44, 43, 56, 39, 52, 41, 43,  1, 47,\n",
      "        57,  1, 39,  1, 45, 39, 47, 52,  1, 58, 53,  1, 58, 46, 43, 51,  1, 24,\n",
      "        43, 58,  1, 59, 57,  1, 56, 43, 60, 43, 52, 45, 43,  1, 58, 46, 47, 57,\n",
      "         1, 61, 47, 58, 46,  0, 53, 59, 56,  1, 54, 47, 49, 43, 57,  6,  1, 43,\n",
      "        56, 43,  1, 61, 43,  1, 40, 43, 41, 53, 51, 43,  1, 56, 39, 49, 43, 57,\n",
      "        10,  1, 44, 53, 56,  1, 58, 46, 43,  1, 45, 53, 42, 57,  1, 49, 52, 53,\n",
      "        61,  1, 21,  0, 57, 54, 43, 39, 49,  1, 58, 46, 47, 57,  1, 47, 52,  1,\n",
      "        46, 59, 52, 45, 43, 56,  1, 44, 53, 56,  1, 40, 56, 43, 39, 42,  6,  1,\n",
      "        52, 53, 58,  1, 47, 52,  1, 58, 46, 47, 56, 57, 58,  1, 44, 53, 56,  1,\n",
      "        56, 43, 60, 43, 52, 45, 43,  8,  0,  0])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(contents), dtype=int)\n",
    "print(data.shape,data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae8d3705-c112-499e-b9bc-1491a914609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[n:]\n",
    "val_data = data[:n]\n",
    "train_data = train_data.float()\n",
    "val_data = val_data.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acf82293-5890-4813-a8c4-c1f9961d2ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now, we define our context window\n",
    "torch.manual_seed(1337)\n",
    "BATCH_SIZE = 4\n",
    "CONTEXT_SIZE = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - CONTEXT_SIZE, (BATCH_SIZE,))\n",
    "    x = torch.stack([data[i:i+CONTEXT_SIZE] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+CONTEXT_SIZE+1] for i in ix])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "46d0e620-c421-41fc-8c2c-a09bbf88329f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[61.,  6.,  1., 52., 53., 58.,  1., 58.],\n",
      "        [56.,  6.,  1., 54., 50., 39., 52., 58.],\n",
      "        [58.,  1., 58., 46., 47., 57.,  1., 50.],\n",
      "        [10.,  0., 32., 46., 43., 56., 43.,  1.]])\n",
      "targets:\n",
      "tensor([[ 6.,  1., 52., 53., 58.,  1., 58., 47.],\n",
      "        [ 6.,  1., 54., 50., 39., 52., 58., 43.],\n",
      "        [ 1., 58., 46., 47., 57.,  1., 50., 47.],\n",
      "        [ 0., 32., 46., 43., 56., 43.,  1., 42.]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "160dd1b6-8242-4e4d-8710-eabed0a835fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## LSTM Model\n",
    "\n",
    "## Short Term Memory Block\n",
    "class stmBlock(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Forget Gate:\n",
    "        self.Wif = nn.Linear(input_dim, hidden_dim, bias = False)\n",
    "        self.Whf = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Input Gate:\n",
    "        self.Wii = nn.Linear(input_dim, hidden_dim, bias = False)\n",
    "        self.Whi = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Candidate Gate:\n",
    "        self.Wic = nn.Linear(input_dim, hidden_dim, bias = False)\n",
    "        self.Whc = nn.Linear(hidden_dim, hidden_dim)\n",
    "\n",
    "        # Output Gate:\n",
    "        self.Wio = nn.Linear(input_dim, hidden_dim, bias = False)\n",
    "        self.Who = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "\n",
    "    def forward(self, x, c_prev = None, h_prev = None):\n",
    "        # If not first block:\n",
    "        if h_prev is not None:\n",
    "            f = self.sigmoid(self.Wif(x) + self.Whf(h_prev))\n",
    "            i = self.sigmoid(self.Wii(x) + self.Whi(h_prev))\n",
    "            c = self.tanh(self.Wic(x) + self.Whc(h_prev))\n",
    "            o = self.sigmoid(self.Wio(x) + self.Who(h_prev))\n",
    "        else:\n",
    "            f = self.sigmoid(self.Wif(x))\n",
    "            i = self.sigmoid(self.Wii(x))\n",
    "            c = self.tanh(self.Wic(x))\n",
    "            o = self.sigmoid(self.Wio(x))\n",
    "\n",
    "        if c_prev == None:\n",
    "            c_t = i * c\n",
    "        else:\n",
    "            c_t = f * c_prev + i * c\n",
    "        h = o * self.tanh(c_t)\n",
    "        return c_t, h\n",
    "\n",
    "## Now for the entire LSTM Module\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.stmBlocks = nn.ModuleList([stmBlock(input_dim, hidden_dim) for i in range(CONTEXT_SIZE)])\n",
    "        # We make an additional list of linear layers for the ouput of each block\n",
    "        self.linLays = nn.ModuleList([nn.Linear(hidden_dim, output_dim) for i in range(CONTEXT_SIZE)])\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        logits = []\n",
    "        h = None\n",
    "        c = None\n",
    "        for i in range(CONTEXT_SIZE):\n",
    "            element = x[:, i].unsqueeze(1)\n",
    "            c, h = self.stmBlocks[i](element, c, h) if h is not None else self.stmBlocks[i](element)\n",
    "            o = self.linLays[i](h)\n",
    "            logits.append(o)\n",
    "        \n",
    "        logits = torch.stack(logits, dim=1)\n",
    "        if targets is not None:\n",
    "            loss = self.loss(logits.view(-1, VOCAB_SIZE), targets.view(-1).long())\n",
    "            return logits, loss\n",
    "        return logits, None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2491b4b0-e433-401f-accf-30e6badf785d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    lossAvg = 0\n",
    "    counter = 0\n",
    "    for i in range(400):\n",
    "        counter+=1\n",
    "        batch = get_batch(\"test\")\n",
    "        logits, loss = model(batch[0], batch[1])\n",
    "        lossAvg += loss.item()\n",
    "    return lossAvg / counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "084b7a64-1062-44c9-9674-79d416f193f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 8688136\n"
     ]
    }
   ],
   "source": [
    "model = LSTM(1, 512, VOCAB_SIZE)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.0001)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9fbb2b5d-44f3-4e1c-bcec-832d688f2591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [09:03<00:00,  5.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  3.1771271228790283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_iterations = 3000\n",
    "for i in tqdm(range(training_iterations)):\n",
    "    optimizer.zero_grad()\n",
    "    batch = get_batch(\"train\")\n",
    "    outputs, loss = model(batch[0], batch[1])\n",
    "    loss.backward()\n",
    "    #print(\"Loss: \", loss.item())\n",
    "    optimizer.step()\n",
    "print(\"Loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c5cd796b-02a8-47e1-9c22-48d5d2ecf888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  2.946816769242287\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss: \", evaluate(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a220dcc5-fb27-48cc-ac7b-f7c9f5de0478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:  r Montag\n",
      " th     \n",
      "Input:  ruchio! \n",
      "      sa\n",
      "Input:  ard him \n",
      "   to  s\n",
      "Input:  your gar\n",
      "    to  \n"
     ]
    }
   ],
   "source": [
    "## Let's do some testing:\n",
    "def infer(input_data):\n",
    "    with torch.no_grad():\n",
    "        outputs, _ = model(input_data)\n",
    "        predicted_indices = torch.argmax(outputs, dim=-1)\n",
    "        return predicted_indices\n",
    "        \n",
    "test_batch = get_batch(\"test\")\n",
    "result = infer(test_batch[0])\n",
    "for i in range(BATCH_SIZE):\n",
    "    print(\"Input: \", decode(test_batch[0].tolist()[i]))\n",
    "    print(decode(result.tolist()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8573d3eb-3b90-49dc-857d-8b8ee5979243",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Truly terrible results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
